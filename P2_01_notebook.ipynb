{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distant-drain",
   "metadata": {},
   "source": [
    "# Optimisation des tournées pour l’entretien des arbres de la ville de Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-sister",
   "metadata": {},
   "source": [
    "![Logo de la ville de Paris](data/image/logo.png)\n",
    "\n",
    "L'objectif est de réaliser une analyse exploratoire à partir du jeu de données de [opendata.paris.fr](https://opendata.paris.fr/explore/dataset/les-arbres/map/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6Imxlcy1hcmJyZXMiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJBVkciLCJ5QXhpcyI6ImlkYmFzZSIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiMwMDMzNjYifV0sInhBeGlzIjoidHlwZWVtcGxhY2VtZW50IiwibWF4cG9pbnRzIjo1MCwic29ydCI6IiJ9XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=13,48.86844,2.30945&basemap=jawg.streets) portant sur les arbres de la ville de Paris, dans le cadre du programme “Végétalisons la ville”.\n",
    "\n",
    "![Végétalisons Paris](data/image/Végétalisation-de-Paris.png)\n",
    "\n",
    "Les résultats contribueront à une optimisation des tournées pour l’entretien des arbres de la ville. Car il y a moins de tournées égales moins il y a de trajets donc plus d’arbres entretenus.\n",
    "\n",
    "Nous commencerons par mettre en place notre environnement de travail. Ensuite nous procèderons à une exploration des données. Puis, un nettoyage de ces données. Par la suite nous les analyserons. De ces analyses nous en ferons des visualisations. Pour finaliser avec une synthèse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-brazilian",
   "metadata": {},
   "source": [
    "## Référentiel d'évaluation\n",
    "\n",
    "### Utiliser des librairies Python pour réaliser une analyse de données exploratoires\n",
    "\n",
    "#### L’analyse de données est **complète** si\n",
    "\n",
    "- [ ] l’environnement de développement est installé et fonctionnel sur le poste de travail (Python et Jupyter)\n",
    "- [ ]  un environnement virtuel a été créé pour assurer l’isolement du projet et la gestion des dépendances\n",
    "- [ ]  les librairies python spécialisé ont été importées dans le Jupyter Notebook\n",
    "- [ ] le jeu de données a été décrit brièvement (nombre de lignes, nombre de colonnes et nombre de valeurs manquantes) en ayant chargé le fichier plat dans un dataframe.\n",
    "\n",
    "#### L’analyse de données est **pertinente** si\n",
    "\n",
    "- [ ] des indicateurs statistiques basiques (moyenne et écart type) ont été calculés pour les différentes colonnes\n",
    "- [ ] les ordres de grandeur des grandeurs statistiques des différentes colonnes ont été comparés\n",
    "\n",
    "#### L’analyse de données est **présentable** si\n",
    "\n",
    "- [ ] les fonctionnalités d’édition de cellule Markdown du Jupyter Notebook sont utilisées dans au moins trois cellules pour commenter l’analyse et la mettre en forme (titres, mise en forme, alternance de cellule d’exécution de code python et de cellule de texte explicatif)\n",
    "- [ ] les titres des trois parties (la présentation générale du jeu de données, la démarche méthodologique d’analyse de données, la synthèse de votre analyse de données) sont visuellement en évidence dans le Jupyter Notebook (par exemple en gras et police de caractère plus grande que dans le reste du document)\n",
    "\n",
    "### Effectuer une analyse statistique univariée\n",
    "\n",
    "#### L’analyse statistique univariée est **complète** si\n",
    "\n",
    "- [ ] les moyennes, médianes et quantiles des distributions sont calculés\n",
    "- [ ] au moins une représentation graphique d’une distribution statistique a été tracée\n",
    "\n",
    "#### L’analyse statistique univariée est **pertinente** si\n",
    "\n",
    "- [ ] les éventuelles valeurs aberrantes ont été identifiées (avec une définition des valeurs aberrantes basée sur un multiple des quantiles de la distribution)\n",
    "\n",
    "#### L’analyse statistique univariée est **présentable** si\n",
    "\n",
    "- [ ] les graphiques sont lisibles (titres alignés, légende présente, noms des abscisses et des ordonnées précisés)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-trout",
   "metadata": {},
   "source": [
    "Notes :\n",
    "\n",
    "1. regarder le jeu de données (string, int.) si les types détectés par pandas sont bien détectés (ex: erreur de conversion date US - FR, décalage..)\n",
    "2. Regarde si les données sont bonnes (aberration)\n",
    "Si elles sont bonnes, faire moyenne, variance, etc. (écart type, etc.)\n",
    "Noter les incohérences\n",
    "Partie traitement\n",
    "supprimer duplicat\n",
    "3. median pour detecter les aberrations (max, min, moyenne, écart-type et médian)\n",
    "4. correction des aberrations (s'assurer qu'il soit le plus clean)\n",
    "5. Feature engineering, clean feature (clean, l'adresse (regarder s'il n'y a pas d'erreur dans l'adresse Mairie 7 = Mairi 7), extraction adresse)\n",
    "6. Réfléchir au pb\n",
    "7. choisir un modèle approprié\n",
    "8. séparé les données (80-20 / 70-30) (loi normale)\n",
    "9. lancer le modèle (control over et under fitting)\n",
    "10. industriel : automatisé, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-contamination",
   "metadata": {},
   "source": [
    "pandas.DataFrame.quantile = remplacer (par 30) ou supprimer\n",
    "ou\n",
    "k-mean\n",
    "\n",
    "analyser corrélation géo + adresse\n",
    "\n",
    "type d'arbres + taille + âgé\n",
    "\n",
    "nb de valeur manquante, aberrante, chiffre graphique\n",
    "\n",
    "pertinent : moyenne, écart type, médiane, moyenne longueur pour chaque catégorie, sélectionner colonne pertinente\n",
    "garder toutes les étapes d'analyses\n",
    "\n",
    "présentable\n",
    "\n",
    "graphique = titre, légende, respecter format\n",
    "analyse multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-communications",
   "metadata": {},
   "source": [
    "## Mise en place de l'environnement de travail\n",
    "\n",
    "![Logo de Conda](data/image/conda.png)\n",
    "\n",
    "Avant de commencer à étudier le sujet, nous allons d'abord mettre en place notre environnement afin de travailler dans des conditions favorables.\n",
    "\n",
    "Dans cette étape nous isolons notre travail dans un environnement virtuel avec toutes les dépendances nécessaire à son fonctionnement à l'aide de l'outil Conda d’Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-repeat",
   "metadata": {},
   "source": [
    "## Chargement des librairies\n",
    "\n",
    "Une fois dans l’environnement virtuel, nous pouvons charger les dépendances nécessaires à la réalisation du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-begin",
   "metadata": {},
   "source": [
    "## Chargement du jeu de données\n",
    "\n",
    "Nous demandons à Pandas, qui est un outil d'analyse de données, de lire le contenu du fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-genre",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/p2-arbres-fr.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-tracy",
   "metadata": {},
   "source": [
    "## Exploration du jeu de données\n",
    "\n",
    "Dans cette étape nous allons explorer le contenu du fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-manitoba",
   "metadata": {},
   "source": [
    "### Dimentionnalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-actor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Le fichier est constitué de {df.shape[0]} lignes et de {df.shape[1]} colonnes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-reflection",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le type de données pour chaque colonne est : \\n\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-wrist",
   "metadata": {},
   "source": [
    "Nous pouvons remarquer l'existance de données manquantes (NULL ou NaN), dont 100% pour la colonne \"numero\".\n",
    "Explorons un peu plus en détail ces données manquantes. Ensuite vérifions si les types correspondent bien aux colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-research",
   "metadata": {},
   "source": [
    "### Données manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.isna().mean().round(4) * 100,\n",
    "             columns=['Données manquante']).sort_values(by='Données manquante',\n",
    "                                                        ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-march",
   "metadata": {},
   "source": [
    "Analysons brièvement les colonnes contenant des valeurs manquantes dans l'ordre décroissant.\n",
    "\n",
    "- **\"numero\"** à 100% : correspond certainement au numéro d'adresse de \"lieu\". La colonne \"lieu\" indiquant déjà l'adresse, il ne semble pas nécessaire de corriger ou conserver cette colonne.\n",
    "- **\"complement_adresse\"** à 84,6% : les adresses ne contiennent pas forcement des compléments, cependant par rapport au lieu ou aux points géographiques nous pouvons déterminer si des compléments sont manquants.\n",
    "- **\"variete\"** à 81,6% : afin de remplir les données manquantes, nous pouvons analyser les colonnes \"libelle_francais\", \"genre\" et \"espece\" qui contiennent des variétés et analyser la corrélation.\n",
    "- **\"stade_developpement\"** à 33,6% : Correspond à l'âge de l'arbre. Il nous est possible d'estimer les valeurs NULL en comparant \"libelle_francais\", \"genre\", \"espece\" ou \"variete\" avec \"circonference_cm\" et \"hauteur_m\".\n",
    "- **\"remarquable\"** à 31,5% : Un arbre remarquable relève d'un patrimoine par sa rareté, ses dimensions, sa position, son âge ou encore sa force symbolique. Certaines valeurs peuvent donc être estimées par des critères concrets comme l'espèce, la hauteur, la dimension, le stade de développement ou la position, mais aussi par des critères abstraits comme le symbole. Comme il est difficile d'estimer une valeur basée sur une notion abstraite il est possible d'améliorer la pertinence en collectant des données externes permettant de remplir ces valeurs.\n",
    "- **\"espece\"** à 0,9%, **\"libelle_francais\"** à 0,7% et **\"genre\"** à 0,01% : Le nombre de valeurs manquantes étant très faible il sera aisé de les remplir en utilisant une méthode similaire à \"variete\".\n",
    "- **\"id\"** à 0% : Les ID sont par définition non nul et unique. La première règle est respectée, nous verrons s'il est de même pour la seconde plus tard.\n",
    "\n",
    "Cette étape nous a permis de développer quelques stratégies permettant de remplir les valeurs manquantes.\n",
    "\n",
    "Cependant avant de pouvoir remplir les données manquantes, il faudra prendre soin d'analyser s'il n'y a pas d’aberration, c'est-à-dire des erreurs, parmi les valeurs présentes et de les corriger si c'est le cas. Nous verrons cela dans les prochaines étapes.\n",
    "\n",
    "Tout d'abord, vérifions si le type de donnée des colonnes correspond bien aux valeurs et analysons leur contenu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-violation",
   "metadata": {},
   "source": [
    "### Type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillon\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-agency",
   "metadata": {},
   "source": [
    "Avant de commencer à analyser la correspondance des types de données, voici un rappel sur les types :\n",
    "- object = Texte ou valeurs numériques et non numériques mixtes\n",
    "- int64 = Nombres entiers\n",
    "- float64 = Nombres à virgule flottante\n",
    "- bool = Valeurs vraies / Faux\n",
    "\n",
    "Que pouvons-nous remarquer ? :\n",
    "- **\"id\"** int64 : Le type correspond. L'ID débute à partir de 99874 et s'incrémente de 1 dans l'ordre croissant.\n",
    "- **\"type_emplacement\"** object: Le type correspond. Les valeurs semblent tous être identique \"Arbre\". Il faudra vérifier les valeurs uniques de cette colonne. Si les données s’avèrent identiques nous pourrons remettre en question son utilité .\n",
    "- **\"domanialite\"** object : Le type correspond. Nous pourrons explorer les valeurs uniques après.\n",
    "- **\"arrondissement\"** object : Le type correspond. Cependant les données pourraient être allégées en indiquant seulement le numéro de l'arrondissement au format int64.\n",
    "- **\"numero\"** float64 : Le type correspond. Cependant ne contient aucune valeur.\n",
    "- **\"lieu\"** object : Le type correspond. Possible de vérifier si l'adresse est correct grâce aux coordonnées géographiques.\n",
    "- **\"id_emplacement\"** object : Le type correspond, néanmoins cette colonne reste étrange. Les ID ne sont pas uniformes. Elles sont généralement de type int64 (ex.: 9) et quelquefois de type object (ex.: 000G0037).\n",
    "- **\"complement_addresse\"**, **\"libelle_francais\"**, **\"genre\"**, **\"espece\"**, **\"variete\"** et **\"stade_developpement\"** object : Le type correspond. Cependant des nombres à virgules auraient été plus adaptés pour éviter d'avoir \"0\" si un arbre mesure moins d'1 mètre. À moins que les valeurs <1 ne soient transformées en 1 par défaut.\n",
    "- **\"circonference_cm\"** et **\"hauteur_m\"** int64 : Le type correspond.\n",
    "- **\"remarquable\"** float64 : Le type ne correspond pas. Il faut le corriger en type bool.\n",
    "- **\"geo_point_2d_a\"**, **\"geo_point_2d_b\"** float64 : Le type correspond.\n",
    "\n",
    "Cette étape nous a appris que même si certains types de données sont exactes nous pouvons tout de même l'optimiser, comme **\"arrondissement\"** par exemple qui peut être allégé par un type int64 ou comme **\"id_emplacement\"** en uniformisant les id en int64 (ex: 000G0037 -> 37).\n",
    "Quant à **\"remarquable\"** il est préférable de le convertir en bool. Réaliser cette conversion trop tôt risquerait de convertir des valeurs NULL en FALSE. Donc cette tâche sera réalisée après avoir rempli les valeurs manquantes.\n",
    "\n",
    "Nous allons donc d'abord vérifier les valeurs uniques des colonnes. Il est possible que d'autres soient dans le cas de **\"type_emplacement\"** et n'ont qu'une seule valeur unique.\n",
    "\n",
    "Ensuite nous pourrons rechercher les duplicate et aberration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de \"remarquable\" en booléen\n",
    "# df['remarquable'] = df['remarquable'].astype('bool')\n",
    "# df['remarquable'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-muslim",
   "metadata": {},
   "source": [
    "### Données uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda col: col.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-basketball",
   "metadata": {},
   "source": [
    "Mis à part \"type_emplacement\" qui ne contient que \"Arbre\" et \"numero\" qui ne contient rien du tout, il n'y a rien de particulier à signaler. Si ce n'est par exemple certain \"domanialite\" tout en majuscule (ex. : CIMETIERE -> Cimetiere)\n",
    "\n",
    "Quant est-il des duplicats ?\n",
    "\n",
    "Compte tenu de la consigne du projet qui suggère de ne pas trop s'attarder sur l’exploration, nous nous limiterons à \"id\" et aux coordonnées géographiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-shakespeare",
   "metadata": {},
   "source": [
    "### Duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des duplicats de \"id\"\n",
    "df[df.duplicated(['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-fisher",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"id\" semble ne pas avoir de duplicat. Nous pouvons donc estimer que cette colonne est correcte, car les id sont actuellement non nuls et uniques.\n",
    "\n",
    "Maintenant, vérifions les coordonnées géographiques, car techniquement 2 arbres ne peuvent pas être exactement au même endroit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-bookmark",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recherche de duplicat dans les coordonnées géographiques\n",
    "df[df.duplicated(['geo_point_2d_a', 'geo_point_2d_b'],\n",
    "                 keep=False)].sort_values([\"geo_point_2d_a\", \"geo_point_2d_b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-wisconsin",
   "metadata": {},
   "source": [
    "L'analyse de ces duplicats nous apprend ceci :\n",
    "- Des arbres sont identiques, mais ont un \"id_emplacement\" qui diffère, très souvent de +1\n",
    "- Certains arbres identiques avec le même \"id_emplacement\" ont des données NULL dans l'un et remplies dans l'autre\n",
    "- Certains arbres ont une espèce différente au même endroit. Peut-être que des arbres ont été remplacés depuis et que le duplicat correspond à un ancien arbre qui n'existe plus. Si c'est le cas, comment reconnaitre le plus récent sans la date ? Peut-être avec \"stade_developpement\" le plus jeune si disponible. Ou plus simplement par l'\"id\" le plus grand.\n",
    "- Des arbres identiques présentent des lieux différents comme \"domanialite\" (ex.: Jardin -> PERIPHERIQUE) et \"id_emplacement\" (1 -> 09VO19001), mais aussi un \"lieu\" identique, mais rédigé différemment (VOIE DF19 -> VOIE \\n DF/19). Il y a certainement une corrélation entre \"domanialite\" et le type de \"id_emplacement\" et la rédaction de \"lieu\".\n",
    "\n",
    "Nous pouvons en conclure que plusieurs moyens différents doivent être employés pour nettoyer les doublons. Cependant vu le faible nombre et le temps disponible nous pouvons les supprimer puis à l'avenir revenir dessus au besoin.\n",
    "La suppression des doublons se fera dans l'étape de nettoyage.\n",
    "\n",
    "Ces différents points nous permettent aussi d'aborder des stratégies de nettoyage globales en dehors des duplicats comme l'uniformisation de \"lieu\" (ex: VOIE \\n DF/19 -> VOIE DF19)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-swing",
   "metadata": {},
   "source": [
    "## Aberration\n",
    "\n",
    "Dans cette partie nous allons analyser les données à la recherche d'incohérences et réfléchir aux possibles solutions à déployer pour les corriger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-associate",
   "metadata": {},
   "source": [
    "### Vue d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-discovery",
   "metadata": {},
   "source": [
    "En se fiant à l'écart type, 2 colonnes sortent du lot : \"circonference_cm\" et \"hauteur_m\".\n",
    "Leurs valeurs max sont en effet aberrant 250 255 centimètres pour la circonférence et 881 818 mètres pour la hauteur. Ces chiffres dépassent de manière évidente la réalité.\n",
    "\n",
    "En ce qui concerne les valeurs égales à 0. Nous pouvons nous demander s'il faut le considérer comme une valeur nulle ou un arbre dont la valeur est inférieure à 1. En effet, le type de la colonne empêche d'afficher des nombres à virgule. Néanmoins, il est improbable d'avoir des arbres avec une circonférence de moins de 1cm. Ce qui remet en question les valeurs égales à 0.\n",
    "\n",
    "Analysons plus en détail ces chiffres pour réfléchir comment résoudre ces valeurs.\n",
    "Par exemple, comment pourrions-nous déterminer à partir de combien de mètres une valeur devient incorrect ?\n",
    "Sachant que ces valeurs ont forcement une corrélation avec l’espèce et l'âge de l'arbre, comment filtrer les valeurs convenablement ?\n",
    "\n",
    "Procédons par étape. Nous pouvons d'abord visualiser ces 2 colonnes dans leur ensemble. Puis démontrer la corrélation évidente des dimensions d'un arbre par rapport à son âge et son espèce. Pour ensuite affiner la détection d'anomalie pour chaque type d'arbres selon leur âge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-mirror",
   "metadata": {},
   "source": [
    "### Analyse globale de la hauteur et de la circonférence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-separate",
   "metadata": {},
   "source": [
    "#### Nombre de valeurs égale à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb0 = df[[\"circonference_cm\", \"hauteur_m\"]]\n",
    "nb0[nb0 == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-ordering",
   "metadata": {},
   "source": [
    "Soit 12,9% des valeurs de circonference_cm sont des 0 et 19.6% pour hauteur_m. Compte tenu de leur nombre et du doute, il serait préférable de les supprimer à l'étape du nettoyage le temps de trouver une meilleure solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-bacteria",
   "metadata": {},
   "source": [
    "#### Identification des valeurs aberrantes avec l'écart interquartile (EI)\n",
    "\n",
    "L'écart interquartile (EI) est une mesure de dispersion statistique et est calculé comme la différence entre les 75e et 25e percentiles. Il est représenté par la formule EI = Q3 - Q1. Les lignes de code ci-dessous calculent et affichent l'écart interquartile pour la circonférence et la hauteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[[\"circonference_cm\", \"hauteur_m\"]].quantile(0.25)\n",
    "Q3 = df[[\"circonference_cm\", \"hauteur_m\"]].quantile(0.75)\n",
    "EI = Q3 - Q1\n",
    "EI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-cradle",
   "metadata": {},
   "source": [
    "La sortie ci-dessus affiche les scores EI, qui peuvent être utilisés pour détecter les valeurs aberrantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-beginning",
   "metadata": {},
   "source": [
    "#### Identification des valeurs aberrantes avec asymétrie\n",
    "\n",
    "Plusieurs algorithmes de Machine Learning partent du principe que les données suivent une distribution normale (ou gaussienne). Ceci est facile à vérifier avec la valeur d'asymétrie (skewness), qui explique dans quelle mesure les données sont distribuées normalement. Idéalement, la valeur d'asymétrie devrait être comprise entre -1 et +1, et tout écart important par rapport à cette plage indique la présence de valeurs extrêmes.\n",
    "\n",
    "La première ligne de code ci-dessous affiche la valeur d'asymétrie pour la variable \"circonference_cm\" et \"hauteur_m\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"circonference_cm\", \"hauteur_m\"]].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-dragon",
   "metadata": {},
   "source": [
    "La valeur d'asymétrie de 298,2 pour \"circonference_cm\" et 447,3 pour \"hauteur_m\" montre une distribution décalée à gauche de la médiane, et donc une queue de distribution étalée vers la droite. Ces valeurs indiquent la présence de valeurs extrêmes élevées. La valeur maximale 250 255 centimètres pour la circonférence et 881 818 mètres pour la hauteur en sont la preuve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-dallas",
   "metadata": {},
   "source": [
    "#### Identifier les valeurs aberrantes avec la visualisation\n",
    "\n",
    "Dans la section précédente, nous avons utilisé des méthodes quantitatives pour l'identification des aberrations. La visualisation va nous permettre d'étoffer cette analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramme et fonction d'estimation de la densité du noyau de la variable \"circonference_cm\"\n",
    "ax = sns.displot(df[\"circonference_cm\"], kde=True)\n",
    "ax.set(xlim=(1, 400))\n",
    "\n",
    "# notation indiquant une éventuelle valeur aberrante\n",
    "# ax.annotate('Possible outlier', xy=(188,0.0030), xytext=(189,0.0070), fontsize=12,\n",
    "#             arrowprops=dict(arrowstyle='->', ec='grey', lw=2), bbox = dict(boxstyle=\"round\", fc=\"0.8\"))\n",
    "\n",
    "# ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# étiquettes et titres\n",
    "plt.xlabel('circonference_cm', fontsize=14)\n",
    "plt.ylabel('fréquence', fontsize=14)\n",
    "plt.title('Distribution de la circonférence en cm', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagramme en boite de la variable \"circonference_cm\".\n",
    "ax = sns.boxplot(x=df[\"circonference_cm\"])\n",
    "ax.set(xlim=(1, 2000))\n",
    "\n",
    "# notation indicating an outlier\n",
    "ax.annotate('Aberration',\n",
    "            xy=(240, 0),\n",
    "            xytext=(300, -0.1),\n",
    "            fontsize=14,\n",
    "            arrowprops=dict(arrowstyle='->', ec='grey', lw=2),\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"0.8\"))\n",
    "\n",
    "# xtick, label, and title\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('circonference_cm', fontsize=14)\n",
    "plt.title('Distribution de la circonférence en cm', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-petite",
   "metadata": {},
   "source": [
    "Dans le résultat ci-dessus, les losanges indiquent les valeurs aberrantes, et elles sont nombreuses. Il est fortement probable que beaucoup de ces ne soient pas réellement aberrante. Ici l'anomalie commence à partir de 240 centimètres de circonférence.\n",
    "\n",
    "Quand est-il de la hauteur ? :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramme et fonction d'estimation de la densité du noyau de la variable \"circonference_cm\"\n",
    "ax = sns.displot(df[\"hauteur_m\"], kde=True)\n",
    "#ax.set(xlim=(0, 400))\n",
    "\n",
    "# notation indiquant une éventuelle valeur aberrante\n",
    "# ax.annotate('Possible outlier', xy=(188,0.0030), xytext=(189,0.0070), fontsize=12,\n",
    "#             arrowprops=dict(arrowstyle='->', ec='grey', lw=2), bbox = dict(boxstyle=\"round\", fc=\"0.8\"))\n",
    "\n",
    "# ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# étiquettes et titres\n",
    "plt.xlabel('hauteur_m', fontsize=14)\n",
    "plt.ylabel('fréquence', fontsize=14)\n",
    "plt.title('Distribution de la hauteur en m', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagramme en boite de la variable \"circonference_cm\".\n",
    "ax = sns.boxplot(x=df[\"hauteur_m\"])\n",
    "ax.set(xlim=(0, 100))\n",
    "\n",
    "# notation indicating an outlier\n",
    "ax.annotate('Aberration',\n",
    "            xy=(23, 0),\n",
    "            xytext=(25, -0.1),\n",
    "            fontsize=14,\n",
    "            arrowprops=dict(arrowstyle='->', ec='grey', lw=2),\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"0.8\"))\n",
    "\n",
    "# xtick, label, and title\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('hauteur_m', fontsize=14)\n",
    "plt.title('Distribution de la hauteur en m', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-attribute",
   "metadata": {},
   "source": [
    "Ici l'anomalie débute à partir de 22 mètres de hauteur.\n",
    "\n",
    "Diagramme de dispersion\n",
    "Les histogrammes et les diagrammes en boite identifient les valeurs qui sont très éloignées des valeurs moyennes pour chaque caractéristique (valeurs aberrantes univariées). Cependant, ils ne permettent pas d'identifier un comportement anormal entre deux ou plusieurs variables (valeurs aberrantes multivariées). C'est là que les diagrammes de dispersion sont utiles."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
